{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import django\n",
    "\n",
    "os.environ['DJANGO_SETTINGS_MODULE']='TweetToEmoji.settings'\n",
    "\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.models import Emoji\n",
    "from nltk.corpus import wordnet \n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TweetsFromResponse(response):\n",
    "    return [t.get('text') for t in response.get('statuses')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db.models import Q\n",
    "def SearchEmoji(keyword):\n",
    "    emoji = Emoji.objects.filter(Q(Name__contains = keyword) | Q(Description__contains = keyword))\n",
    "    return ''.join([e.Icon+str(e.Id)+e.Name for e in emoji])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindSynonyms(word):\n",
    "    syns = wordnet.synsets(word) \n",
    "    synonym_list =[s.lemma_names() for s in syns ] # take synonyms name\n",
    "    synonym_list = [item.replace('_',' ') for sublist in synonym_list for item in sublist] # flatten list\n",
    "    synonym_list= set(synonym_list) # remove duplicates\n",
    "    return list(synonym_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterService.Client import TwitterClient\n",
    "\n",
    "client = TwitterClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = client.Get('search/tweets.json', lang = 'en', q='climate', result_type = 'popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "content = client.GetFromHistory(\"04-11-2018 17.06.12.391\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Do you like blowing bubbles? So does our Milky Way galaxy—although these bubbles might be a little bigger than what… https://t.co/6phvpfpsCu',\n",
       " 'A new record for our mission to \"touch\" the Sun, the end of an era for a prolific planet hunter, and our… https://t.co/01mTidYbPb',\n",
       " \"10x the diameter of Earth, this solar prominence rising up above the Sun's surface was spotted by our Solar Dynamic… https://t.co/hCvHTE4fDD\",\n",
       " \"What’s up in the sky this month? You can't miss bright Venus in the predawn hours, Saturn at sunset, Mars in the ev… https://t.co/dOU284ZPmH\",\n",
       " 'Want to feel the rumble of the next @SpaceX launch to the @Space_Station from @NASAKennedy in Florida? Apply to att… https://t.co/K711eFRLFY',\n",
       " '😉 Can you find the smiling face in this patch of space, captured by @NASAHubble? The unprecedented resolution of Hu… https://t.co/tns73STv7N',\n",
       " 'James Harden arrives wearing the @heronpreston NASA collection. Parka ($1,897), hoodie sweatshirt ($556) and tech p… https://t.co/0K1F3A67ub',\n",
       " 'Witness our @OSIRISREx spacecraft’s steady approach toward the asteroid Bennu. 👀 During the last half of October, t… https://t.co/Gsgidr1fBG',\n",
       " '.@NASAInSight has to flawlessly perform thousands of steps in order to travel from the top of Mars’ atmosphere to t… https://t.co/n9UDFZI1A2',\n",
       " 'Did you know 232 different people have lived and worked aboard the space station? Right now, it is home (and work!)… https://t.co/kKvOaTfOSN',\n",
       " 'Calling all social media users! Want to witness &amp; share the experience of @SpaceX’s next cargo launch to… https://t.co/HcQcwSUzh2',\n",
       " 'Who needs glue when you have lasers? Our team of optic physicists at @NASAGoddard are using an ultrafast laser that… https://t.co/lAnmuBPRZc',\n",
       " \"NASA's Parker Solar Probe broke the world record for the closest approach to the sun ever achieved by a man-made sp… https://t.co/9puAiQYfV0\",\n",
       " 'Efforts to detect technologically advanced life predates the Space Age. But the question still remains: Are we alon… https://t.co/1ytCt5xAYI']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = TweetsFromResponse(content)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Burns',\n",
       " 'George Burns',\n",
       " 'Nathan Birnbaum',\n",
       " 'Robert Burns',\n",
       " 'bite',\n",
       " 'burn',\n",
       " 'burn down',\n",
       " 'burn mark',\n",
       " 'burn off',\n",
       " 'burn up',\n",
       " 'burning',\n",
       " 'cauterise',\n",
       " 'cauterize',\n",
       " 'combust',\n",
       " 'cut',\n",
       " 'fire',\n",
       " 'glow',\n",
       " 'incinerate',\n",
       " 'sting',\n",
       " 'sunburn',\n",
       " 'suntan',\n",
       " 'tan'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FindSynonyms(\"burns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TagOf(word):\n",
    "    return pos_tag([s])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs is NN\n",
      "track(NN) -> 🌸1729 Cherry Blossom🚈1926 Light Rail🚝1929 Monorail🛤1954 Railway Track🚟1976 Suspension Railway🖲2171 Trackball🔖2207 Bookmark🔀2390 Shuffle Tracks Button🔁2391 Repeat Button🔂2392 Repeat Single Button⏭2395 Next Track Button⏮2399 Last Track Button\n",
      "wienerwurst(NN) -> \n",
      "weenie(NN) -> \n",
      "blackguard(NN) -> \n",
      "give chase(NN) -> \n",
      "frank(NN) -> \n",
      "tag(NN) -> 🌷1737 Tulip🛑1960 Stop Sign⚡2052 High Voltage#2448 Keycap Number Sign🔣2465 Input Symbols\n",
      "click(NN) -> \n",
      "dog(NN) -> 🥺90 Pleading Face🙇844 Person Bowing🦴1554 Bone🐶1629 Dog Face🐕1630 Dog🐩1631 Poodle🐾1678 Paw Prints🌭1793 Hot Dog\n",
      "heel(NN) -> 🤸1220 Person Cartwheeling🤸1226 Man Cartwheeling🤸1232 Woman Cartwheeling🥿1612 Flat Shoe👠1613 High-Heeled Shoe👡1614 Woman’s Sandal👢1615 Woman’s Boot🍭1835 Lollipop🎡1916 Ferris Wheel🛴1949 Kick Scooter🧳1983 Luggage🎰2119 Slot Machine♿2320 Wheelchair Symbol☸2369 Wheel of Dharma\n",
      "andiron(NN) -> \n",
      "hound(NN) -> \n",
      "pawl(NN) -> \n",
      "frankfurter(NN) -> \n",
      "tail(NN) -> 👧142 Girl👩160 Woman🐒1627 Monkey🐩1631 Poodle🐈1636 Cat🐿1670 Chipmunk🦕1701 Sauropod🦖1702 T-Rex🍸1845 Cocktail Glass🍹1846 Tropical Drink🏦1886 Bank🏆2082 Trophy📇2248 Card Index🔭2293 Telescope\n",
      "bounder(NN) -> \n",
      "cad(NN) -> 👾104 Alien Monster🥑1767 Avocado🍫1833 Chocolate Bar\n",
      "wiener(NN) -> \n",
      "Canis familiaris(NN) -> \n",
      "frump(NN) -> \n",
      "firedog(NN) -> \n",
      "detent(NN) -> \n",
      "chase(NN) -> 🛍1607 Shopping Bags📼2185 Videocassette\n",
      "go after(NN) -> \n",
      "chase after(NN) -> \n",
      "hot dog(NN) -> 🌭1793 Hot Dog\n",
      "dog-iron(NN) -> \n",
      "domestic dog(NN) -> \n",
      "hotdog(NN) -> \n",
      "trail(NN) -> \n"
     ]
    }
   ],
   "source": [
    "word=\"dogs\"\n",
    "syn = FindSynonyms(word)\n",
    "print(word +' is ' + TagOf(word))\n",
    "for s in syn:\n",
    "    print('{0}({1}) -> {2}'.format(s, TagOf(s), SearchEmoji(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\leven\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateCombinations(words):\n",
    "    list = []\n",
    "    for slen in range(1, len(words)):\n",
    "        for sshift in range(0, len(words) - slen):\n",
    "            list.append(words[sshift:slen + sshift])\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(sentence):\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    return nltk.pos_tag(tokenized_text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertTweet(tweet):\n",
    "    sentences = sent_tokenize(tweet)\n",
    "    words=Tokenize(sentences[0])\n",
    "    combinations = GenerateCombinations(words)\n",
    "    combinations = sorted(combinations, key=len, reverse=True)\n",
    "    print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Do', 'VBP'), ('you', 'PRP'), ('like', 'IN'), ('blowing', 'VBG'), ('bubbles', 'NNS')], [('Do', 'VBP'), ('you', 'PRP'), ('like', 'IN'), ('blowing', 'VBG')], [('you', 'PRP'), ('like', 'IN'), ('blowing', 'VBG'), ('bubbles', 'NNS')], [('Do', 'VBP'), ('you', 'PRP'), ('like', 'IN')], [('you', 'PRP'), ('like', 'IN'), ('blowing', 'VBG')], [('like', 'IN'), ('blowing', 'VBG'), ('bubbles', 'NNS')], [('Do', 'VBP'), ('you', 'PRP')], [('you', 'PRP'), ('like', 'IN')], [('like', 'IN'), ('blowing', 'VBG')], [('blowing', 'VBG'), ('bubbles', 'NNS')], [('Do', 'VBP')], [('you', 'PRP')], [('like', 'IN')], [('blowing', 'VBG')], [('bubbles', 'NNS')]]\n"
     ]
    }
   ],
   "source": [
    "ConvertTweet(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "405.844px",
    "left": "614.141px",
    "right": "20px",
    "top": "131px",
    "width": "480px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
